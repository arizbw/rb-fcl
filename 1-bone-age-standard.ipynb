{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the VGG16 model\n",
    "\n",
    "# plot feature map of first conv layer for given image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import Model\n",
    "from matplotlib import pyplot\n",
    "from numpy import expand_dims\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "from keras.preprocessing import image\n",
    "from models.keras import ModelFactory\n",
    "import numpy as np\n",
    "import os\n",
    "from configparser import ConfigParser\n",
    "from PIL import Image\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parser config\n",
    "#config_file = \"./config.ini\"\n",
    "config_file = \"crop-InceptionResNetV2/config.ini\"\n",
    "cp = ConfigParser()\n",
    "cp.read(config_file)\n",
    "output_dir = cp[\"DEFAULT\"].get(\"output_dir\")\n",
    "base_model_name = cp[\"DEFAULT\"].get(\"base_model_name\")\n",
    "class_names = cp[\"DEFAULT\"].get(\"class_names\").split(\",\")\n",
    "image_source_dir = cp[\"DEFAULT\"].get(\"image_source_dir\")\n",
    "output_weights_name = cp[\"TRAIN\"].get(\"output_weights_name\")\n",
    "weights_path = os.path.join(output_dir, output_weights_name)\n",
    "best_weights_path = os.path.join(output_dir, f\"best_{output_weights_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\"\"\"\n",
    "from models.keras import ModelFactory\n",
    "model_factory = ModelFactory()\n",
    "model = model_factory.get_model(\n",
    "    class_names,\n",
    "    model_name=base_model_name,\n",
    "    use_base_weights=False,\n",
    "    weights_path=best_weights_path)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_model = Model(inputs=model.inputs,outputs=model.layers[780].output)\n",
    "temp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#temp_model = Model(inputs=model.inputs,outputs=model.layers[310].output)\n",
    "temp_model.save('my_model-inception-resnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # which gpu to use\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error as sk_mae\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True # dont allocate entire vram initially\n",
    "set_session(tf.Session(config=config))\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, Flatten, Concatenate\n",
    "from keras.models import Sequential,Model\n",
    "from keras.metrics import mean_absolute_error\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import pdb\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "#Reading data\n",
    "print(\"Reading data...\")\n",
    "#pdb.set_trace()\n",
    "img_dir = 'boneage-training-dataset/boneage-training-dataset/'\n",
    "csv_path = 'boneage-training-dataset.csv'\n",
    "age_df = pd.read_csv(csv_path)\n",
    "print (age_df.head(10))\n",
    "\n",
    "\n",
    "age_df['path'] = age_df['id'].map(lambda x: img_dir+\"{}.png\".format(x))\n",
    "age_df['exists'] = age_df['path'].map(os.path.exists)\n",
    "age_df['gender'] = age_df['male'].map(lambda x: \"male\" if x else \"female\")\n",
    "print (age_df['gender'].head(10))\n",
    "print (age_df['exists'].head(10))\n",
    "print (age_df['path'].head(10))\n",
    "\n",
    "\n",
    "\n",
    "mu = age_df['boneage'].mean()\n",
    "sigma = age_df['boneage'].std()\n",
    "print (mu)\n",
    "print (sigma)\n",
    "age_df['zscore'] = age_df['boneage'].map(lambda x: (x-mu)/sigma)\n",
    "print (age_df['zscore'].head(10))\n",
    "age_df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "#Examine the distribution of age and gender\n",
    "print(\"{} images found out of total {} images\".format(age_df['exists'].sum(),age_df.shape[0]))\n",
    "print(age_df.sample(5))\n",
    "age_df[['boneage','gender','zscore']].hist()\n",
    "plt.show()\n",
    "print(\"Reading complete !!!\\n\")\n",
    "\n",
    "#Split into training testing and validation datasets\n",
    "print(\"Preparing training, testing and validation datasets ...\")\n",
    "age_df['boneage_category'] = pd.cut(age_df['boneage'], 10)\n",
    "raw_train_df, test_df = train_test_split(age_df, \n",
    "                                   test_size = 0.2, \n",
    "                                   random_state = 2018,\n",
    "                                   stratify = age_df['boneage_category'])\n",
    "raw_train_df, valid_df = train_test_split(raw_train_df, \n",
    "                                   test_size = 0.1,\n",
    "                                   random_state = 2018,\n",
    "                                   stratify = raw_train_df['boneage_category'])\n",
    "\n",
    "\n",
    "# Balance the distribution in the training set\n",
    "train_df = raw_train_df.groupby(['boneage_category','gender']).apply(lambda x: x.sample(500, replace = True)).reset_index(drop=True)\n",
    "print(train_df.sample(5))\n",
    "train_df[['boneage','gender']].hist(figsize = (10, 5))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "train_size = train_df.shape[0]\n",
    "valid_size = valid_df.shape[0]\n",
    "test_size = test_df.shape[0]\n",
    "print(\"# Training images:   {}\".format(train_size))\n",
    "print(\"# Validation images: {}\".format(valid_size))\n",
    "print(\"# Testing images:    {}\".format(test_size))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMG_SIZE = (299, 299) # default size for inception_v3\n",
    "\n",
    "core_idg = ImageDataGenerator(samplewise_center=False, \n",
    "                              samplewise_std_normalization=False, \n",
    "                              horizontal_flip = True, \n",
    "                              vertical_flip = False, \n",
    "                              height_shift_range = 0.15, \n",
    "                              width_shift_range = 0.15, \n",
    "                              rotation_range = 5, \n",
    "                              shear_range = 0.01,\n",
    "                              fill_mode = 'nearest',\n",
    "                              zoom_range=0.25,\n",
    "                             preprocessing_function = preprocess_input)\n",
    "\n",
    "\n",
    "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n",
    "    base_dir = os.path.dirname(in_df[path_col].values[0])\n",
    "    print('## Ignore next message from keras, values are replaced anyways')\n",
    "    df_gen = img_data_gen.flow_from_directory(base_dir, \n",
    "                                     class_mode = 'sparse',\n",
    "                                    **dflow_args)\n",
    "    df_gen.filenames = in_df[path_col].values\n",
    "    df_gen.classes = np.stack(in_df[y_col].values)\n",
    "    df_gen.samples = in_df.shape[0]\n",
    "    df_gen.n = in_df.shape[0]\n",
    "    df_gen._set_index_array()\n",
    "    df_gen.directory = '' # since we have the full path\n",
    "    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n",
    "    return df_gen\n",
    "\n",
    "\n",
    "\n",
    "train_gen = flow_from_dataframe(core_idg, train_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'zscore',\n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = 32)\n",
    "\n",
    "valid_gen = flow_from_dataframe(core_idg, valid_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'zscore', \n",
    "                              \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = 32) # we can use much larger batches for evaluation\n",
    "# used a fixed dataset for evaluating the algorithm\n",
    "test_X, test_Y = next(flow_from_dataframe(core_idg, \n",
    "                              test_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'zscore', \n",
    "                                \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = 1024))\n",
    "\n",
    "\n",
    "\n",
    "t_x, t_y = next(train_gen)\n",
    "fig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\n",
    "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n",
    "    c_ax.imshow(c_x[:,:,0], cmap = 'bone', vmin = -127, vmax = 127)\n",
    "    c_ax.set_title('%2.0f months' % (c_y*sigma+mu))\n",
    "    c_ax.axis('off')\n",
    "\n",
    "\n",
    "print (t_x.shape[1:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modePredictions = Model(inputs=model.inputs, outputs=model.layers[311].output)\n",
    "modePredictions.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Compiling deep model ...\")\n",
    "img = Input(t_x.shape[1:])\n",
    "cnn_vec = InceptionV3(input_shape = t_x.shape[1:], include_top = False, weights = 'my_model.h5')(img)\n",
    "cnn_vec = GlobalAveragePooling2D()(cnn_vec)\n",
    "#cnn_vec = Dropout(0.2)(cnn_vec)\n",
    "dense_layer = Dense(1024, activation = 'relu')(cnn_vec)\n",
    "#dense_layer = Dropout(0.2)(dense_layer)\n",
    "#dense_layer = Dense(1024,activation='relu')(dense_layer)\n",
    "#dense_layer = Dropout(0.2)(dense_layer)\n",
    "output_layer = Dense(1, activation = 'linear')(dense_layer) # linear is what 16bit did\n",
    "bone_age_model = Model(inputs=img,outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mae_months(in_gt, in_pred):\n",
    "    return mean_absolute_error(mu+sigma*in_gt, mu+sigma*in_pred)\n",
    "  \n",
    "bone_age_model.compile(optimizer = 'adam', loss = 'mse', metrics = [mae_months])\n",
    "bone_age_model.summary()\n",
    "print(\"Model compiled !!!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights.besttf.hdf5\".format('bone_age')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1,save_best_only=True, mode='min', save_weights_only = True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10) # probably needs to be more patient, but kaggle time is limited\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]\n",
    "\n",
    "\n",
    "bone_age_model.fit_generator(train_gen,\n",
    "                                  steps_per_epoch = train_size/10,\n",
    "                                  validation_data = (test_X,test_Y),\n",
    "                                  epochs = 25, \n",
    "                                  callbacks = callbacks_list)\n",
    "\n",
    "bone_age_model.load_weights(weight_path)\n",
    "print(\"Training complete !!!\\n\")\n",
    "\n",
    "#Evaluate model on test dataset\n",
    "print(\"Evaluating model on test data ...\\n\")\n",
    "print(\"Preparing testing dataset...\")\n",
    "test_X, test_Y = next(flow_from_dataframe(core_idg,test_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'zscore',\n",
    "                            batch_size = 1024,\n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb'))\n",
    "                             # one big batch\n",
    "print(\"Data prepared !!!\")\n",
    "\n",
    "pred_Y = mu+sigma*bone_age_model.predict(x=test_X,batch_size=25,verbose=1)\n",
    "test_Y_months = mu+sigma*test_Y\n",
    "print(\"Mean absolute error on test data: \"+str(sk_mae(test_Y_months,pred_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chexnet",
   "language": "python",
   "name": "chexnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
